{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Attention Visualization Playground\n",
    "\n",
    "This notebook allows you to interact with a sentiment classification model that uses attention mechanisms to identify important parts of sentences. The model has been trained on the SST-2 (Stanford Sentiment Treebank) dataset, which consists of movie reviews annotated with binary sentiment labels.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to load and use a pre-trained sentiment analysis model\n",
    "- How to visualize attention weights to see which words the model focuses on\n",
    "- How to analyze model predictions and confidence scores\n",
    "- How attention mechanisms work in natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Import model and visualization modules\n",
    "from models.model import SentimentClassificationModel\n",
    "from visualization.attention_viz import visualize_multiple_examples, analyze_attention_patterns\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model and Tokenizer\n",
    "\n",
    "Let's load the pre-trained model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU, CUDA, or MPS)\n",
    "# Uncomment the appropriate line for your system\n",
    "device = torch.device(\"cpu\")  # Default to CPU\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  # CUDA (NVIDIA GPUs)\n",
    "# device = torch.device(\"mps\") if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() else torch.device(\"cpu\")  # MPS (Apple Silicon)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Initialize model with the same parameters as the training configuration\n",
    "model = SentimentClassificationModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=config.embedding_dim,\n",
    "    hidden_dim=config.hidden_dim,\n",
    "    output_dim=config.output_dim,\n",
    "    pad_idx=tokenizer.pad_token_id,\n",
    "    bidirectional=True  # Using bidirectional GRU as in the trained model\n",
    ")\n",
    "\n",
    "# Load the pre-trained weights\n",
    "checkpoint_path = \"weights/2025-04-15_11-13-14__last.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Sentences for Visualization\n",
    "\n",
    "Here are some example sentences with different sentiments. Feel free to modify this list or add your own examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"I love this movie. It's amazing!\",\n",
    "    \"This is the worst movie I've ever seen.\",\n",
    "    \"The plot was boring and predictable.\",\n",
    "    \"The acting was top-notch and the cinematography was stunning.\",\n",
    "    \"I wouldn't recommend this film to anyone.\"\n",
    "]\n",
    "\n",
    "# You can add or modify sentences here\n",
    "# example_sentences.append(\"Your own sentence goes here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Attention Weights\n",
    "\n",
    "Now let's visualize the attention weights for each of our example sentences. The attention weights show which words the model focuses on when making its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention weights for the example sentences\n",
    "fig = visualize_multiple_examples(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    example_sentences,\n",
    "    device,\n",
    "    figsize=(15, 4*len(example_sentences))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Attention Patterns\n",
    "\n",
    "We can also perform a more detailed analysis of the attention patterns across all the example sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = analyze_attention_patterns(model, tokenizer, example_sentences, device)\n",
    "\n",
    "# Display the results in a more readable format\n",
    "for i, result in enumerate(analysis_results):\n",
    "    print(f\"\\nSentence {i+1}: {result['sentence']}\")\n",
    "    print(f\"Prediction: {result['prediction']} (Confidence: {result['confidence']:.4f})\")\n",
    "    print(f\"Token with highest attention: '{result['max_attention_token']}' (Attention: {result['max_attention_value']:.4f})\")\n",
    "    print(f\"Mean attention: {result['mean_attention']:.4f}, Std: {result['std_attention']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Prediction\n",
    "\n",
    "Let's create a simple function to make predictions on new sentences interactively."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def predict_sentiment(sentence):\n    \"\"\"Predict the sentiment of a sentence and visualize attention weights.\"\"\"\n    # Tokenize the sentence\n    token_ids = tokenizer.encode(sentence, add_special_tokens=True)\n    input_ids = torch.tensor([token_ids]).to(device)\n    \n    # Make prediction\n    with torch.no_grad():\n        outputs, attention_weights = model(input_ids, return_attention=True)\n    \n    # Get probabilities and prediction\n    probs = torch.nn.functional.softmax(outputs, dim=1)\n    predicted_class = torch.argmax(probs, dim=1).item()\n    confidence = probs[0][predicted_class].item()\n    sentiment = \"Positive\" if predicted_class == 1 else \"Negative\"\n    \n    # Print prediction and confidence\n    print(f\"Sentence: '{sentence}'\")\n    print(f\"Prediction: {sentiment} (Confidence: {confidence:.4f})\")\n    \n    # Get tokens for visualization\n    tokens = [tokenizer.convert_ids_to_tokens(id) for id in token_ids]\n    \n    # Extract attention weights\n    attention = attention_weights.squeeze(0).cpu().numpy()\n    \n    # Ensure attention is in the right shape for visualization\n    if len(attention.shape) == 1:\n        attention = attention.reshape(1, -1)\n    \n    # Find token with maximum attention\n    if len(attention.shape) == 2:\n        flat_idx = np.argmax(attention)\n        # Convert flat index to 2D coordinates\n        row_idx, col_idx = np.unravel_index(flat_idx, attention.shape)\n        max_attention_idx = col_idx\n        max_attention_value = attention[row_idx, col_idx]\n    else:\n        max_attention_idx = np.argmax(attention)\n        max_attention_value = attention[max_attention_idx]\n        \n    max_attention_token = tokens[max_attention_idx]\n    print(f\"Token with highest attention: '{max_attention_token}' (Attention: {max_attention_value:.4f})\")\n    \n    # Visualize attention\n    plt.figure(figsize=(12, 3))\n    sns.heatmap(\n        attention,\n        cmap=\"YlOrRd\",\n        annot=True,\n        fmt=\".3f\",\n        cbar=False,\n        xticklabels=tokens,\n        yticklabels=[\"Attention\"]\n    )\n    plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    plt.title(f\"Prediction: {sentiment} (Confidence: {confidence:.4f})\")\n    plt.tight_layout()\n    plt.show()\n    \n    return sentiment, confidence, attention"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "Now you can try the model on your own sentences. Type in any sentence, and the model will predict its sentiment and show which words it's focusing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with your own sentence\n",
    "your_sentence = \"The food at this restaurant was absolutely delicious and the service was excellent!\"\n",
    "predict_sentiment(your_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Different Sentences\n",
    "\n",
    "Try different types of sentences and see how the model performs. Here are some suggestions:\n",
    "\n",
    "1. Use sentences with clear positive or negative sentiment\n",
    "2. Try more neutral sentences\n",
    "3. Use sentences with negation (\"not bad\", \"isn't great\")\n",
    "4. Try sentences with mixed sentiment\n",
    "\n",
    "See which words get the highest attention in each case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with some more examples\n",
    "sentences_to_try = [\n",
    "    \"The movie wasn't bad at all.\",\n",
    "    \"This book is not particularly exciting, but it's informative.\",\n",
    "    \"While I enjoyed the beginning, the ending was disappointing.\",\n",
    "    \"Despite some flaws, the overall experience was positive.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences_to_try:\n",
    "    predict_sentiment(sentence)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Attention Works in This Model\n",
    "\n",
    "The attention mechanism in this model works by assigning weights to different words in the input sentence. These weights represent how important each word is for the final sentiment prediction.\n",
    "\n",
    "Here's a simplified explanation of how the attention mechanism works:\n",
    "\n",
    "1. The input sentence is first processed by an embedding layer and then by a GRU (Gated Recurrent Unit) layer, which produces hidden states for each word.\n",
    "2. The attention mechanism calculates a score for each hidden state, indicating its importance.\n",
    "3. These scores are normalized using a softmax function to create attention weights that sum to 1.\n",
    "4. The final context vector is a weighted sum of all hidden states, where the weights are the attention weights.\n",
    "5. This context vector is then used for the final prediction.\n",
    "\n",
    "The attention weights visualized in the heatmaps above show which words the model focused on when making its prediction. Words with higher attention weights have a stronger influence on the model's decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored a sentiment classification model that uses attention mechanisms to focus on important words in sentences. We've seen how attention weights can provide interpretability, showing us which parts of the input the model is focusing on when making predictions.\n",
    "\n",
    "Key takeaways:\n",
    "- Attention mechanisms help models focus on relevant parts of the input\n",
    "- Visualizing attention weights provides insights into model decision-making\n",
    "- The model tends to focus on words with strong sentiment polarity\n",
    "- Understanding attention can help us build more interpretable and effective NLP models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}